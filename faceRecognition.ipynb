{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Face recognition using LBPH recognizer algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from PIL import Image,ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the ID:: 0\n"
     ]
    }
   ],
   "source": [
    "# Image ID\n",
    "ID = int(input(\"Enter the ID:: \"))\n",
    "\n",
    "# Name\n",
    "Name = input(\"Enter the Name:: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Path\n",
    "IMAGE_PATH = \"/home/christ-infotech-007/PycharmProjects/pythonProject6/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Turning on the live stream using web cam (-1 for LINUX, 0 for WINDOW, and 1 for MAC-OS)\n",
    "\n",
    "source = cv2.VideoCapture(-1)\n",
    "detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Size\n",
    "sampleNum=300\n",
    "\n",
    "#Image Number\n",
    "frame_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the loop\n",
    "for sample in range(sampleNum):\n",
    "  \n",
    "    # extracting the frames\n",
    "    ret, img = source.read()\n",
    "      \n",
    "    # converting to gray-scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = detector.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        \n",
    "        #Increament the image number\n",
    "        frame_num+=1\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        imgname = os.path.join(IMAGE_PATH,Name+\".\"+str(ID)+\".\"+f'{str(frame_num)}.jpg')\n",
    "        cv2.imwrite(imgname, gray)\n",
    "        # displaying the video\n",
    "        cv2.imshow(\"Frame\", gray)\n",
    "    \n",
    "    \n",
    "      \n",
    "# closing the window\n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create images and labels for training\n",
    "\n",
    "def getImagesAndLabels(path):\n",
    "    imagePaths = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "    # create empth face list\n",
    "    faceSamples = []\n",
    "    # create empty ID list\n",
    "    Ids = []\n",
    "    # now looping through all the image paths and loading the Ids and the images\n",
    "    for imagePath in imagePaths:\n",
    "        # loading the image and converting it to gray scale\n",
    "        pilImage = Image.open(imagePath).convert('L')\n",
    "        # Now we are converting the PIL image into numpy array\n",
    "        imageNp = np.array(pilImage, 'uint8')\n",
    "        # getting the Id from the image\n",
    "\n",
    "        Id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        # extract the face from the training image sample\n",
    "        faces = detector.detectMultiScale(imageNp)\n",
    "        # If a face is there then append that in the list as well as Id of it\n",
    "        for (x, y, w, h) in faces:\n",
    "            faceSamples.append(imageNp[y:y + h, x:x + w])\n",
    "            Ids.append(Id)\n",
    "    return faceSamples, Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recognizing face\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/home/christ-infotech-007/PycharmProjects/pythonProject6/dataset\"\n",
    "faces, Id = getImagesAndLabels(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "recognizer.train(faces, np.array(Id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "recognizer.save(\"model/trained_model2.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model with web cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 49\u001B[0m\n\u001B[1;32m     37\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mputText(\n\u001B[1;32m     38\u001B[0m                 img, \n\u001B[1;32m     39\u001B[0m                 \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m), \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     44\u001B[0m                 \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m     45\u001B[0m                )\n\u001B[1;32m     48\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcamera\u001B[39m\u001B[38;5;124m'\u001B[39m,img) \n\u001B[0;32m---> 49\u001B[0m k \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwaitKey\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m0xff\u001B[39m \u001B[38;5;66;03m# Press 'ESC' for exiting video\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m27\u001B[39m:\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#loading the model\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('model/trained_model2.yml')\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "id = 0\n",
    "\n",
    "# add the list of names of your dataset here\n",
    "names = ['rohan'] \n",
    "\n",
    "\n",
    "cam = cv2.VideoCapture(-1)\n",
    "\n",
    "while True:\n",
    "    ret, img =cam.read()\n",
    "    #img = cv2.flip(img, -1) # Flip vertically\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = faceCascade.detectMultiScale( \n",
    "        gray,\n",
    "        scaleFactor = 1.2,\n",
    "        minNeighbors = 5\n",
    "       )\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        \n",
    "        # If confidence is less them 100 ==> \"0\" : perfect match \n",
    "        if (confidence < 100):\n",
    "            id = names[id]\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        else:\n",
    "            id = \"unknown\"\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        \n",
    "        cv2.putText(\n",
    "                    img, \n",
    "                    str(id), \n",
    "                    (x+5,y-5), \n",
    "                    font, \n",
    "                    1, \n",
    "                    (255,255,255), \n",
    "                    2\n",
    "                   )\n",
    "         \n",
    "    \n",
    "    cv2.imshow('camera',img) \n",
    "    k = cv2.waitKey(10) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
