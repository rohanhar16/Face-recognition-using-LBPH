{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Face recognition using LBPH recognizer algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from PIL import Image,ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the ID:: 1\n",
      "Enter the Name:: rohan\n"
     ]
    }
   ],
   "source": [
    "# Image ID\n",
    "ID = int(input(\"Enter the ID:: \"))\n",
    "\n",
    "# Name\n",
    "Name = input(\"Enter the Name:: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Path\n",
    "IMAGE_PATH = \"/home/christ-infotech-007/PycharmProjects/pythonProject6/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Turning on the live stream using web cam (-1 for LINUX, 0 for WINDOW, and 1 for MAC-OS)\n",
    "\n",
    "source = cv2.VideoCapture(-1)\n",
    "detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Size\n",
    "sampleNum=300\n",
    "\n",
    "#Image Number\n",
    "frame_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the loop\n",
    "for sample in range(sampleNum):\n",
    "  \n",
    "    # extracting the frames\n",
    "    ret, img = source.read()\n",
    "      \n",
    "    # converting to gray-scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = detector.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        \n",
    "        #Increament the image number\n",
    "        frame_num+=1\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        imgname = os.path.join(IMAGE_PATH,Name+\".\"+f'{str(frame_num)}.jpg')\n",
    "        cv2.imwrite(imgname, gray)\n",
    "        # displaying the video\n",
    "        cv2.imshow(\"Frame\", gray)\n",
    "    \n",
    "    \n",
    "      \n",
    "# closing the window\n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create images and labels for training\n",
    "\n",
    "def getImagesAndLabels(path):\n",
    "    imagePaths = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "    # create empth face list\n",
    "    faceSamples = []\n",
    "    # create empty ID list\n",
    "    Ids = []\n",
    "    # now looping through all the image paths and loading the Ids and the images\n",
    "    for imagePath in imagePaths:\n",
    "        # loading the image and converting it to gray scale\n",
    "        pilImage = Image.open(imagePath).convert('L')\n",
    "        # Now we are converting the PIL image into numpy array\n",
    "        imageNp = np.array(pilImage, 'uint8')\n",
    "        # getting the Id from the image\n",
    "\n",
    "        Id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        # extract the face from the training image sample\n",
    "        faces = detector.detectMultiScale(imageNp)\n",
    "        # If a face is there then append that in the list as well as Id of it\n",
    "        for (x, y, w, h) in faces:\n",
    "            faceSamples.append(imageNp[y:y + h, x:x + w])\n",
    "            Ids.append(Id)\n",
    "    return faceSamples, Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recognizing face\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/home/christ-infotech-007/PycharmProjects/pythonProject6/dataset\"\n",
    "faces, Id = getImagesAndLabels(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "recognizer.train(faces, np.array(Id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "recognizer.save(\"model/trained_model2.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
